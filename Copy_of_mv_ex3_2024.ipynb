{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cQT6vUuvoQv"
   },
   "source": [
    "# Machine Vision - Exercise 3\n",
    "\n",
    "<!--\n",
    "Automation and Control Institute - TU Wien\n",
    "Matthias Hirschmanner 2023\n",
    "machinevision@acin.tuwien.ac.at\n",
    " -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDx1jdP-C4rx"
   },
   "source": [
    "In this exercise you will implement a neural network to classify images of the CIFAR10 dataset (https://www.cs.toronto.edu/~kriz/cifar.html). It consists of 60000 images with a resolution of 32x32. The different classes and example images for each classes are shown in Figure 1 below. We will use the library PyTorch to create and train neural networks.\n",
    "\n",
    "\n",
    "![Classes of CIFAR10](https://owncloud.tuwien.ac.at/index.php/apps/files_sharing/ajax/publicpreview.php?x=1064&y=425&a=true&file=ex4_cifar10_2.png&t=PfJAai8huq9AWRa)\n",
    "\n",
    "Figure 1: Examples of the different classes of the CIFAR10 dataset.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "Please keep the code in the sections below clean and only change it in the dedicated areas. You shouldn't need to change it anywhere else. You also shouldn't need to use any additional libraries other than the ones already imported. If you need to change the code somewhere else or need to import a different library to get a functioning program, that might be a bug. Please report it in the Tuwel forum or send us a mail to machinevision@acin.tuwien.ac.at\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NR6xh3rKFDa1"
   },
   "source": [
    "## Import Libraries\n",
    "In a first step we import the libraries needed for the exercise. Please execute the cell below."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "M3ijYWKmK7V7"
   },
   "source": [
    "import os\n",
    "import random\n",
    "import requests\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import imageio\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "get_ipython().__class__.__name__ = \"ZMQInteractiveShell\"\n",
    "\n",
    "print('Torch', torch.__version__, 'CUDA', torch.version.cuda)\n",
    "if torch.cuda.is_available():\n",
    "    print('Device:', torch.cuda.get_device_name(0))\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gI4YH9vUX7Kg"
   },
   "source": [
    "After executing this cell, it should show that you are using a \"cuda\" device. This means you can run code on the GPU. If this is not the case, change the runtime to GPU.\n",
    "\n",
    "**Since Google Colab seems to be a bit more restrictive with the GPU than in previous years, I recommend to do the first parts of the exercise only with CPU and switch to GPU once you train your CNN model (7. Convolutional Neural Network).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bP3zba8JYLjG"
   },
   "source": [
    "## PyTorch\n",
    "The first step of the exercise is mainly aimed at getting familiar with the PyTorch library and how it works. We will use it to define and train neural networks. The main data structure of PyTorch are tensors. They are very similar to NumPy arrays, but can run on GPUs or other hardware accelerators. Tensors are optimized for automatic differentiation which we will use for gradient descent to optimize the parameters/weights of an network."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QwOrrY50YKke"
   },
   "source": [
    "# Demo of creating a tensor from a numpy array and then moving it to the GPU.\n",
    "a_np = np.array([[1,2],[3,4]])\n",
    "print(a_np)\n",
    "a_t = torch.from_numpy(a_np)\n",
    "print(a_t)\n",
    "a_t_gpu = a_t.to(device)\n",
    "print(a_t_gpu)\n",
    "\n",
    "b_np = np.array([[1,2],[3,4]])\n",
    "b_t = torch.from_numpy(a_np)\n",
    "\n",
    "# This would not work, because b_t is on the CPU and a_t on the GPU\n",
    "# print(b_t*a_t_gpu)\n",
    "\n",
    "print(b_t.to(device)*a_t_gpu)\n",
    "a = 4\n",
    "print(a)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3W2JKiKgfIks"
   },
   "source": [
    "When we apply functions on our tensors, PyTorch (or more specifically autograd) keeps a record of all tensors, operations and resulting new tensors in a directed acyclic graph (DAG) also called the Computational Graph. It also supports automatically calculating the gradients of all tensors using backpropagation (which is the fancy term to apply the chain rule). For an introduction to these computational graphs and how to calculate gradients, see https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html. For a good introduction to backpropagation, you can watch this video which is also linked in the tutorial above: https://youtu.be/tIeHLnjs5U8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Z0WecubF8ag"
   },
   "source": [
    "##1. Linear Regression and Gradient Descent (3 Points)\n",
    "As a first step to get to know PyTorch and using its automatic differentiation engine, you will implement linear regression with a neural network. Linear regression refers to the method of fitting a linear model to approximate some input data. In other words, we want to find the coefficients of a function $w_1x_1+w_2x_2+\\dots +w_nx_n+b=y$ to minimize the distance of our input data to the estimated values. There are many methods that are better suited to solve this problem, e.g. Least Squares or RANSAC (which we will implement in exercise 5). However, to get familiar with neural networks, we will solve this task with a 1 layer neural network and Gradient Descent. The network is shown in Figure 2.\n",
    "\n",
    "Implement the function `linear_regression` which takes as input the array $\\mathbf{X}$ and vector $\\mathbf{y}$ and returns the coefficients of the linear model $(w_1,w_2,\\dots,w_n,b)^T$. You should perform gradient descent to minimize the loss function to estimate these coefficients. As a loss function, use the (mean) squared distance. You should use tensors and the PyTorch's autograd engine. Do not use a built-in optimizer, but implement a simple gradient descent yourself.\n",
    "\n",
    "Tipp: When updating the weights/coefficients use `with torch.no_grad():`, otherwise PyTorch will also keep track of these functions and its gradients. After updating the weights with the gradients, set them to 0, otherwise PyTorch adds up future gradients.\n",
    "\n",
    "![Linear Model](https://owncloud.tuwien.ac.at/index.php/apps/files_sharing/ajax/publicpreview.php?x=1023&y=400&a=true&file=ex4_linearmodel.png&t=A4cyYi3Lgrp1MXM&scalingup=0)\n",
    "\n",
    "Figure 2: Linear model visualized as a one layer neural network.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "i5zPN9uZMzsV"
   },
   "source": [
    "def linear_regression(x_in: np.ndarray,\n",
    "                      y_in: np.ndarray,\n",
    "                      learning_rate: float = 0.01,\n",
    "                      epochs: int = 30) -> Tuple[np.ndarray, np.ndarray]:\n",
    "  \"\"\" Calculate the coefficients of the linear model w1x1+w2x2+...+wnxn+b = y\n",
    "      to fit the input data using gradient descent.\n",
    "\n",
    "  :param x_in: The independent variables x. Each row is related to one datapoint.\n",
    "  :type x_in: np.ndarray with shape (data_points, nr. of independent variables)\n",
    "\n",
    "  :param y_in: The dependent variable y. Each row is related to one datapoint.\n",
    "  :type y_in: np.ndarray with shape (data_points, 1)\n",
    "\n",
    "  :param learning_rate: The coefficient to update the weights per gradient\n",
    "    descent iteration.\n",
    "  :type learning_rate: float in (0,1)\n",
    "\n",
    "  :param epochs: Number of times the whole dataset is used for gradient descent-\n",
    "  :type epochs: int > 0\n",
    "\n",
    "  :return: (coefficients, loss_history)\n",
    "    coefficients: The coefficients of the linear model (w1,w2,...,wn,b)\n",
    "    loss_history: Array with the mean squared loss per epoch.\n",
    "  :rtype:\n",
    "    coefficients: np.ndarray (w1,w2,...,wn,b) with shape (nr. of ind. variables + 1,)\n",
    "    loss_history: np.ndarray (loss_ep1, loss_ep2, ... loss_epn) with shape (epoch,)\n",
    "  \"\"\"\n",
    "  ###################################\n",
    "  # Write your own code here #\n",
    "  X = torch.tensor(x_in, dtype=torch.float32)\n",
    "  y = torch.tensor(y_in, dtype=torch.float32)\n",
    "\n",
    "  num = X.shape[1]\n",
    "\n",
    "  w = torch.zeros(num, requires_grad=True, dtype=torch.float32)\n",
    "  b= torch.zeros(1, requires_grad=True, dtype=torch.float32)\n",
    "  losses = np.zeros(epochs)\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "      y_pred = X @ w + b\n",
    "      loss = torch.mean((y_pred - y)**2)\n",
    "      loss.backward()\n",
    "\n",
    "      with torch.no_grad():\n",
    "          w -= learning_rate * w.grad\n",
    "          b -= learning_rate * b.grad\n",
    "\n",
    "      w.grad.zero_()\n",
    "      b.grad.zero_()\n",
    "\n",
    "      losses[epoch] = loss.item()\n",
    "  coefficients = np.concatenate((w.detach().numpy(), b.detach().numpy()), axis = 0)\n",
    "  ###################################\n",
    "  return coefficients, losses"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTVUtBL3-nMU"
   },
   "source": [
    "Below we apply your linear regression algorithm. You might need to change the learning rate or the number of epochs to get good results, depending on the details of your implementation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dQEeu00iRg9M"
   },
   "source": [
    "# Adapt these parameters if necessary\n",
    "learning_rate = 0.01\n",
    "epochs = 30\n",
    "\n",
    "# Generate random data\n",
    "x_in = np.random.rand(100, 3)\n",
    "\n",
    "# Extend with ones to add the constant factor in one operation\n",
    "x_in_homogeneous = np.c_[x_in, np.ones(100)]\n",
    "\n",
    "# Generate random coefficients w1, w2, w3, b\n",
    "coeff_in = np.random.randint(-10, 10, 4)\n",
    "\n",
    "# Generate noise from a Normal Distribution.\n",
    "# Might be helpful to repmove noise for debugging\n",
    "noise = np.random.randn(100)\n",
    "\n",
    "# Calculate y\n",
    "y_in = np.dot(x_in_homogeneous, coeff_in) + noise\n",
    "y_in = np.expand_dims(y_in, axis = 1)\n",
    "\n",
    "# Apply linear regression\n",
    "# Depending on your implementation, you might need to change your learning rate!\n",
    "coefficients, losses = linear_regression(x_in,\n",
    "                                         y_in,\n",
    "                                         learning_rate = learning_rate,\n",
    "                                         epochs = epochs)\n",
    "\n",
    "# Plot the output per dimension\n",
    "f = plt.figure()\n",
    "f, axes = plt.subplots(nrows = 1,\n",
    "                       ncols = x_in.shape[1],\n",
    "                       sharex= True,\n",
    "                       sharey = True,\n",
    "                       figsize=(15,5))\n",
    "\n",
    "t = np.array([0,1])\n",
    "\n",
    "\n",
    "axes[0].scatter(x_in[:,0],\n",
    "                x_in[:,0] * coeff_in[0] + coeff_in[3] + noise,\n",
    "                marker = \"o\")\n",
    "axes[0].plot(t, t * coefficients[0] + coefficients[3], color = 'red')\n",
    "axes[0].set_xlabel('x_1')\n",
    "\n",
    "axes[1].scatter(x_in[:,1],\n",
    "                x_in[:,1] * coeff_in[1] + coeff_in[3] + noise,\n",
    "                marker = \"o\")\n",
    "axes[1].plot(t, t * coefficients[1] + coefficients[3], color = 'red')\n",
    "axes[1].set_xlabel('x_2')\n",
    "\n",
    "axes[2].scatter(x_in[:,2],\n",
    "                x_in[:,2] * coeff_in[2] + coeff_in[3] + noise,\n",
    "                marker = \"o\")\n",
    "axes[2].plot(t, t * coefficients[2] + coefficients[3], color = 'red')\n",
    "axes[2].set_xlabel('x_3')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "print(y_in.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbt_cqeLHFxH"
   },
   "source": [
    "## Load Dataset\n",
    "In this exercise we will experiment with different neural networks to classify the images of the CIFAR10 dataset. First, we load the CIFAR10 dataset. The training images are in `trainset` and the test images in `testset`. We also create dataloaders for both sets. For more information how to use the datasets and dataloaders you can check https://pytorch.org/tutorials/beginner/basics/data_tutorial.html.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qb4lbED_HJYA"
   },
   "source": [
    "# Load datasets\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                        train=True,\n",
    "                                        download=True,\n",
    "                                        transform=transforms.ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=128,\n",
    "                                          shuffle=True,\n",
    "                                          pin_memory = True,\n",
    "                                          num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                       train=False,\n",
    "                                       download=True,\n",
    "                                       transform=transforms.ToTensor())\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                         batch_size=1024,\n",
    "                                         shuffle=False,\n",
    "                                         pin_memory = True,\n",
    "                                         num_workers=2)\n",
    "\n",
    "\n",
    "# Define the class labels dictionary\n",
    "class_labels = {0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat',\n",
    "                4: 'deer', 5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NB4hSktI1oNA"
   },
   "source": [
    "#@title Run this cell!\n",
    "#@markdown It will show you 9 random images of the dataset.\n",
    "#@markdown The code itself is not relevant, but it is important for later to execute this cell because some plotting functions are defined here.\n",
    "fig, axs = plt.subplots(3, 3,figsize=(10,10))\n",
    "random_indices = np.random.randint(testset.data.shape[0], size=9)\n",
    "for (idx,ax) in zip(random_indices,axs.flat):\n",
    "  ax.set_title(class_labels[testset.targets[idx]])\n",
    "  ax.imshow(testset.data[idx])\n",
    "\n",
    "# Helper function for one-hot encoding labels\n",
    "def one_hot_encode(labels, num_classes):\n",
    "    return F.one_hot(labels, num_classes).float()\n",
    "\n",
    "def plot_predictions(dataloader: torch.utils.data.DataLoader,\n",
    "                     model_name: torch.nn.Module,\n",
    "                     class_name: str = None,\n",
    "                     sort_predictions: bool = False,\n",
    "                     labels: Dict = None,\n",
    "                     num_batches: int = np.inf):\n",
    "    \"\"\" Plot the predictions for some random images. If class_name is set, it will be images of this class\n",
    "\n",
    "    :param dataloader: The dataloader you want to to load the images\n",
    "    :type dataloader: torch.utils.data.DataLoader\n",
    "\n",
    "    :param model_name: Your PyTorch module you want to use to predict labels\n",
    "    :type model_name: torch.nn.Module\n",
    "\n",
    "    :param class_name: Define if you are interested in the predictions of one specific class, e.g. \"dog\"\n",
    "    :type class_name: str\n",
    "\n",
    "    :param sort_predictions: If True, plots the images with the highest prediction values. Otherwise random\n",
    "    :type sort_predictions: bool\n",
    "\n",
    "    :param num_batches: The number of batches we will load with the dataloader. Can help to reduce used memory.\n",
    "    :type num_batches: int\n",
    "\n",
    "    :param labels: The dictionary that assigns each class number a specific label.\n",
    "    :type labels: Dict\n",
    "\n",
    "    :return: None\n",
    "    :rtype: None\n",
    "    \"\"\"\n",
    "\n",
    "    if num_batches <= 0:\n",
    "        raise ValueError(\"The argument num_batches has to be above 0\")\n",
    "\n",
    "    if labels:\n",
    "        labels_inv = {v: k for k, v in labels.items()}\n",
    "\n",
    "    if next(model_name.parameters()).is_cuda:\n",
    "        device = 'cuda'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "\n",
    "    # If the dataset involves some normalization, we need to \"unnormalize\" the\n",
    "    # images again for plotting. There is probably a better solution for it.\n",
    "    unnormalize = None\n",
    "    if isinstance(dataloader.dataset.transform,\n",
    "                  torchvision.transforms.transforms.Compose):\n",
    "      for t in dataloader.dataset.transform.transforms:\n",
    "        if isinstance(t, torchvision.transforms.transforms.Normalize):\n",
    "          unnormalize = transforms.Normalize((-np.array(t.mean) / np.array(t.std)).tolist(), (1.0 / np.array(t.std)).tolist())\n",
    "\n",
    "    if unnormalize:\n",
    "      to_img_transform = transforms.Compose([unnormalize,\n",
    "                                            transforms.ToPILImage()])\n",
    "    else:\n",
    "      to_img_transform = transforms.ToPILImage()\n",
    "\n",
    "    # Set the model to eval() compared to train\n",
    "    model_name.eval()\n",
    "\n",
    "    # We go through our data and store it\n",
    "    # (storing all the images can use a lot of memory, but should work fine for CIFAR10)\n",
    "    y_predictions_tens = torch.empty([0, 10])\n",
    "    y_true_tens = torch.empty([0, ])\n",
    "    x_tens = None\n",
    "    for batch_idx, (x, y) in enumerate(dataloader):\n",
    "        with torch.no_grad():\n",
    "            if batch_idx + 1 > num_batches:\n",
    "                break\n",
    "            pred = F.softmax(model_name(x.to(device)), dim=1)\n",
    "            y_predictions_tens = torch.cat((y_predictions_tens, pred.cpu()))\n",
    "            y_true_tens = torch.cat(((y_true_tens), y.cpu()))\n",
    "            if not isinstance(x_tens, torch.Tensor):\n",
    "              x_tens = x.clone()\n",
    "            else:\n",
    "              x_tens = torch.cat((x_tens, x))\n",
    "\n",
    "    # Get the predicted labels for all images\n",
    "    y_predictions_labels = y_predictions_tens.argmax(dim=1)\n",
    "\n",
    "    # Get a boolean mask for all images that were correctly classified\n",
    "    mask_true_predictions = (y_predictions_labels == y_true_tens)\n",
    "\n",
    "    if class_name and labels:\n",
    "        class_number = labels_inv.get(class_name, -1)\n",
    "        if class_number != -1:  # taking only predictions with defined class_name\n",
    "\n",
    "            # Boolean Mask of images that were correctly predicted with class_name\n",
    "            class_mask_correct = (y_true_tens[mask_true_predictions] == class_number)\n",
    "\n",
    "            # Boolean Mask of images that are images of the class_name, but were wrongly predicted (false negatives)\n",
    "            class_mask_false_negatives = (y_true_tens[~mask_true_predictions] == class_number)\n",
    "\n",
    "            # Boolean Mask of images that were predicted as class_name, but are of a different class (false positives)\n",
    "            class_mask_false_positives = (y_predictions_labels[~mask_true_predictions] == class_number)\n",
    "\n",
    "            print('Number of correct recognized', class_name, 'images is', class_mask_correct.sum().numpy())\n",
    "            print('Number of images recognized as', class_name, 'but are not of that class is',\n",
    "                  class_mask_false_positives.sum().numpy())\n",
    "            print('Number of images not recognized as', class_name, 'but actually are of that class is',\n",
    "                  class_mask_false_negatives.sum().numpy())\n",
    "        else:\n",
    "            print('No such class like', class_name + '. Check class name again.')\n",
    "    else:\n",
    "        print('Number of correct recognized images:', mask_true_predictions.sum().numpy())\n",
    "        print('Number of wrong recognized images:', (~mask_true_predictions).sum().numpy())\n",
    "\n",
    "    images_per_row = 10  # Number of images we want to plot per row\n",
    "    if class_name and labels:\n",
    "        if class_number != -1:\n",
    "            fig = plt.figure(figsize=(20, 7.5))\n",
    "\n",
    "            ######################################################################################################\n",
    "            # First we want to plot images that were correctly classified\n",
    "\n",
    "            # We sample indices of the images to plot.\n",
    "            # If sort_predictions = True, we will plot the images with the highest prediction value\n",
    "            if sort_predictions:\n",
    "                idx_correct_sorted = y_predictions_tens[mask_true_predictions][class_mask_correct].max(\n",
    "                    dim=1).values.argsort(descending=True)\n",
    "                idx_correct = idx_correct_sorted[:images_per_row]\n",
    "\n",
    "            # If sort_predictions = False, we sample random indices\n",
    "            else:\n",
    "                perm = torch.randperm(class_mask_correct.sum())\n",
    "                idx_correct = perm[:images_per_row]\n",
    "\n",
    "            # Apply our generated Boolean masks to get the sampled images that were correctly identified\n",
    "            x_samples = x_tens[mask_true_predictions][class_mask_correct][idx_correct]\n",
    "\n",
    "            # Get the predicted class number (if we did everything correct, it should only return class_number)\n",
    "            y_samples = y_predictions_labels[mask_true_predictions][class_mask_correct][idx_correct]\n",
    "\n",
    "            # Get the Softmax prediction values of the sampled images\n",
    "            y_prediction_samples = y_predictions_tens[mask_true_predictions][class_mask_correct][idx_correct]\n",
    "\n",
    "            # Get the max value of the prediction values\n",
    "            # y_prediction_right_samples = y_prediction_samples[range(len(y_samples)), y_samples]\n",
    "            y_prediction_samples_max = y_prediction_samples.max(dim=1).values\n",
    "\n",
    "            # Plot it\n",
    "            for idx in range(len(x_samples)):\n",
    "                a = fig.add_subplot(3, 10, idx + 1)\n",
    "                imgplot = plt.imshow(to_img_transform(x_samples[idx]))\n",
    "                a.set_title(\n",
    "                    labels[int(y_samples[idx])] + \"\\n p=\" + str(y_prediction_samples_max[idx].numpy().round(4)),\n",
    "                    color='green',\n",
    "                    y=-0.35)\n",
    "                a.axis('off')\n",
    "\n",
    "            ######################################################################################################\n",
    "            # Next, we want to plot false positives - Images that are classified as the specific class,\n",
    "            # but actually belong to a different class.\n",
    "\n",
    "            # We sample indices of the images to plot.\n",
    "            # If sort_predictions = True, we will plot the images with the highest prediction value\n",
    "            if sort_predictions:\n",
    "                idx_false_positive_sorted = y_predictions_tens[~mask_true_predictions][\n",
    "                    class_mask_false_positives].max(dim=1).values.argsort(descending=True)\n",
    "                idx_false_positive = idx_false_positive_sorted[:images_per_row]\n",
    "\n",
    "            # If sort_predictions = False, we sample random indices\n",
    "            else:\n",
    "                perm = torch.randperm(class_mask_false_positives.sum())\n",
    "                idx_false_positive = perm[:images_per_row]\n",
    "\n",
    "            # Apply our generated Boolean masks to get the sampled images that are false positives\n",
    "            x_samples = x_tens[~mask_true_predictions][class_mask_false_positives][idx_false_positive]\n",
    "\n",
    "            # Get the predicted class number (if we did everything correct, it should only return class_number)\n",
    "            y_samples = y_predictions_labels[~mask_true_predictions][class_mask_false_positives][idx_false_positive]\n",
    "\n",
    "            # Get the Softmax prediction values of the sampled images\n",
    "            y_prediction_samples = y_predictions_tens[~mask_true_predictions][class_mask_false_positives][\n",
    "                idx_false_positive]\n",
    "\n",
    "            # Get the max value of the prediction values\n",
    "            # y_prediction_samples_max = y_prediction_samples[range(len(y_samples)), y_samples] # Does the same\n",
    "            y_prediction_samples_max = y_prediction_samples.max(dim=1).values\n",
    "\n",
    "            # Plot it\n",
    "            for idx in range(len(x_samples)):\n",
    "                a = fig.add_subplot(3, 10, idx + images_per_row + 1)\n",
    "                imgplot = plt.imshow(to_img_transform(x_samples[idx]))\n",
    "                if labels:\n",
    "                  a.set_title(\n",
    "                      labels[int(y_samples[idx])] + \"\\n p=\" + str(y_prediction_samples_max[idx].numpy().round(4)),\n",
    "                      color='red',\n",
    "                      y=-0.35)\n",
    "                else:\n",
    "                  a.set_title(\n",
    "                    f\"Class {int(y_samples[idx])}\" + \"\\n p=\" + str(y_prediction_samples_max[idx].numpy().round(4)),\n",
    "                    color='red',\n",
    "                    y=-0.35)\n",
    "                a.axis('off')\n",
    "\n",
    "            ######################################################################################################\n",
    "            # Next, we want to plot false negatives - Images that are of the specific class,\n",
    "            # but were classified as a different class.\n",
    "\n",
    "            # We sample indices of the images to plot.\n",
    "            # If sort_predictions = True, we will plot the images with the highest prediction value\n",
    "            if sort_predictions:\n",
    "                idx_false_negatives_sorted = y_predictions_tens[~mask_true_predictions][\n",
    "                    class_mask_false_negatives].max(dim=1).values.argsort(descending=True)\n",
    "                idx_false_negatives = idx_false_negatives_sorted[:images_per_row]\n",
    "            else:\n",
    "                perm = torch.randperm(class_mask_false_negatives.sum())\n",
    "                idx_false_negatives = perm[:images_per_row]\n",
    "\n",
    "            # Apply our generated Boolean masks to get the sampled images that are false negatives\n",
    "            x_samples = x_tens[~mask_true_predictions][class_mask_false_negatives][idx_false_negatives]\n",
    "\n",
    "            # Get the predicted class number\n",
    "            y_samples = y_predictions_labels[~mask_true_predictions][class_mask_false_negatives][\n",
    "                idx_false_negatives]\n",
    "\n",
    "            # Get the Softmax prediction values of the sampled images\n",
    "            y_prediction_samples = y_predictions_tens[~mask_true_predictions][class_mask_false_negatives][\n",
    "                idx_false_negatives]\n",
    "\n",
    "            # Get the max value of the prediction values\n",
    "            # y_prediction_samples_max = y_prediction_samples[range(len(y_samples)), y_samples] # Does the same\n",
    "            y_prediction_samples_max = y_prediction_samples.max(dim=1).values\n",
    "\n",
    "            # Plot it\n",
    "            for idx in range(len(x_samples)):\n",
    "                a = fig.add_subplot(3, 10, idx + 2 * images_per_row + 1)\n",
    "                imgplot = plt.imshow(to_img_transform(x_samples[idx]))\n",
    "                if labels:\n",
    "                  a.set_title(\n",
    "                      labels[int(y_samples[idx])] + \"\\n p=\" + str(y_prediction_samples_max[idx].numpy().round(3)),\n",
    "                      color='red',\n",
    "                      y=-0.35)\n",
    "                else:\n",
    "                  a.set_title(\n",
    "                      f\"Class {int(y_samples[idx])}\" + \"\\n p=\" + str(y_prediction_samples_max[idx].numpy().round(3)),\n",
    "                      color='red',\n",
    "                      y=-0.35)\n",
    "                a.axis('off')\n",
    "            ######################################################################################################\n",
    "\n",
    "            plt.figtext(0.5, 0.885, \"Correct Predictions\", ha=\"center\", va=\"top\", fontsize=14)\n",
    "            plt.figtext(0.5, 0.62, \"False Positives\", ha=\"center\", va=\"top\", fontsize=14)\n",
    "            plt.figtext(0.5, 0.35, \"False Negatives\", ha=\"center\", va=\"top\", fontsize=14)\n",
    "\n",
    "    # If no class_name was given, plot random images of all classes\n",
    "    else:\n",
    "\n",
    "        ######################################################################################################\n",
    "        # First we want to plot images that were correctly classified\n",
    "\n",
    "        # We sample indices of the images to plot.\n",
    "        # If sort_predictions = True, we will plot the images with the highest prediction value\n",
    "        fig = plt.figure(figsize=(20, 5))\n",
    "        if sort_predictions:\n",
    "            idx_correct_sorted = y_predictions_tens[mask_true_predictions].max(dim=1).values.argsort(\n",
    "                descending=True)\n",
    "            idx_correct = idx_correct_sorted[:images_per_row]\n",
    "\n",
    "        # If sort_predictions = False, we sample random indices\n",
    "        else:\n",
    "            perm = torch.randperm(mask_true_predictions.sum())\n",
    "            idx_correct = perm[:images_per_row]\n",
    "\n",
    "        # Apply our generated Boolean masks to get the sampled images that were correctly identified\n",
    "        x_samples = x_tens[mask_true_predictions][idx_correct]\n",
    "\n",
    "        # Get the Softmax prediction values of the sampled images\n",
    "        y_prediction_samples = y_predictions_tens[mask_true_predictions][idx_correct]\n",
    "\n",
    "        # Get the max value of the prediction values\n",
    "        y_samples_max = y_prediction_samples.max(dim=1)\n",
    "        for idx in range(len(x_samples)):\n",
    "            a = fig.add_subplot(2, 10, idx + 1)\n",
    "            imgplot = plt.imshow(to_img_transform(x_samples[idx]))\n",
    "            if labels:\n",
    "              a.set_title(\n",
    "                  labels[int(y_samples_max.indices[idx])] + \"\\n p=\" + str(\n",
    "                      y_samples_max.values[idx].numpy().round(4)),\n",
    "                  color='green',\n",
    "                  y=-0.35)\n",
    "            else:\n",
    "              a.set_title(\n",
    "                  f\"Class {int(y_samples_max.indices[idx])}\" + \"\\n p=\" + str(\n",
    "                      y_samples_max.values[idx].numpy().round(4)),\n",
    "                  color='green',\n",
    "                  y=-0.35)\n",
    "            a.axis('off')\n",
    "         ######################################################################################################\n",
    "        # Next we want to plot images that were classified as a different class\n",
    "\n",
    "        # We sample indices of the images to plot.\n",
    "        # If sort_predictions = True, we will plot the images with the highest prediction value\n",
    "        if sort_predictions:\n",
    "            idx_false_sorted = y_predictions_tens[~mask_true_predictions].max(dim=1).values.argsort(\n",
    "                descending=True)\n",
    "            idx_false = idx_false_sorted[:images_per_row]\n",
    "\n",
    "        # If sort_predictions = False, we sample random indices\n",
    "        else:\n",
    "            perm = torch.randperm((~mask_true_predictions).sum())\n",
    "            idx_false = perm[:images_per_row]\n",
    "\n",
    "        # Apply our generated Boolean masks to get the sampled images that were correctly identified\n",
    "        x_samples = x_tens[~mask_true_predictions][idx_false]\n",
    "\n",
    "        # Get the Softmax prediction values of the sampled images\n",
    "        y_prediction_samples = y_predictions_tens[~mask_true_predictions][idx_false]\n",
    "\n",
    "        # Get the max value of the prediction values\n",
    "        y_samples_max = y_prediction_samples.max(dim=1)\n",
    "\n",
    "        for idx in range(len(x_samples)):\n",
    "            a = fig.add_subplot(2, 10, idx + 11)\n",
    "            imgplot = plt.imshow(to_img_transform(x_samples[idx]))\n",
    "            if labels:\n",
    "              a.set_title(\n",
    "                  labels[int(y_samples_max.indices[idx])] + \"\\n p=\" + str(\n",
    "                      y_samples_max.values[idx].numpy().round(4)),\n",
    "                  color='red',\n",
    "                  y=-0.35)\n",
    "            else:\n",
    "              a.set_title(\n",
    "                  f\"Class {int(y_samples_max.indices[idx])}\" + \"\\n p=\" + str(\n",
    "                      y_samples_max.values[idx].numpy().round(4)),\n",
    "                  color='red',\n",
    "                  y=-0.35)\n",
    "            a.axis('off')\n",
    "\n",
    "        plt.figtext(0.5, 0.88, \"Correct Predictions\", ha=\"center\", va=\"top\", fontsize=14)\n",
    "        plt.figtext(0.5, 0.465, \"False Predictions\", ha=\"center\", va=\"top\", fontsize=14)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Predict the Top-5 Softmax Scores for an input image.\n",
    "# You can provide a transformation.\n",
    "# Otherwise the image will be transformed to FloatTensor and divided by 255.\n",
    "def predict_image(model_name, image, labels = None, transform = None):\n",
    "  \"\"\" Predict the Top-5 Softmax Scores for an input image. You can provide a transformation;\n",
    "  otherwise, the image will be transformed to FloatTensor and divided by 255.\n",
    "\n",
    "  :param model_name: The PyTorch model used to predict the labels.\n",
    "  :type model_name: torch.nn.Module\n",
    "\n",
    "  :param image: The input image to predict, provided as a numpy array.\n",
    "  :type image: np.ndarray\n",
    "\n",
    "  :param labels: Optional dictionary mapping class indices to human-readable labels.\n",
    "  :type labels: Dict[int, str], optional\n",
    "\n",
    "  :param transform: Optional transformation to apply to the image before prediction.\n",
    "                    If not provided, the image is converted to a FloatTensor and normalized by 255.\n",
    "  :type transform: torchvision.transforms.Compose, optional\n",
    "\n",
    "  :return: None\n",
    "  :rtype: None\n",
    "  \"\"\"\n",
    "\n",
    "  # Extend by one dimension, since the model expects a batch of images\n",
    "  if len(image.shape) == 3:\n",
    "      image = np.expand_dims(image, axis = 0)\n",
    "\n",
    "\n",
    "  # You can provide a transformation which should be applied to the image.\n",
    "  # If no transformation is provided, the image is converted to FloatTensor and\n",
    "  # divided by 255.\n",
    "  if transform:\n",
    "    try:\n",
    "      img_torch = torch.unsqueeze(transform(image[0]),0)\n",
    "    except:\n",
    "      print(\"An error occurred. Make sure transform is of type torchvision.transforms.transforms.Compose\")\n",
    "  else:\n",
    "    img_torch = torch.from_numpy(np.transpose(image.astype(np.float32), (0,3,1,2))/255.)\n",
    "  model_name.eval()\n",
    "  test_prediction = F.softmax(model_name(img_torch.to(device)), dim=1) # define a model of nn\n",
    "  # top 5 predictions\n",
    "  out_ind_up = sorted(range(len(list(test_prediction[0]))), key = lambda sub: test_prediction[0][sub])[-5:]\n",
    "  # result\n",
    "\n",
    "  print(\"Top-5 Predictions:\")\n",
    "  for i in out_ind_up[::-1]:\n",
    "    print()\n",
    "    if labels:\n",
    "      print(' ',\n",
    "            labels[i].capitalize(),\n",
    "            '-',\n",
    "            round((test_prediction[0,i].cpu().detach().numpy())*100,2),\n",
    "            '%')\n",
    "    else:\n",
    "      print(' ',\n",
    "            f'Class {i}',\n",
    "            '-',\n",
    "            round((test_prediction[0,i].cpu().detach().numpy())*100,2),\n",
    "            '%')\n",
    "\n",
    "def load_image_link(link):\n",
    "  \"\"\" Load an image from a URL link, resize it to CIFAR-10 resolution (32x32), and add a batch dimension.\n",
    "\n",
    "  :param link: The URL link to the image you want to load.\n",
    "  :type link: str\n",
    "\n",
    "  :return: The loaded and resized image as a numpy array with an added batch dimension.\n",
    "  :rtype: np.ndarray\n",
    "  \"\"\"\n",
    "\n",
    "  response = requests.get(link)\n",
    "  im_from_link = Image.fromarray(imageio.imread((response.content)))\n",
    "  # Adjust width and height to CIFAR10 resolution\n",
    "  width = 32\n",
    "  height = 32\n",
    "  loaded_image = im_from_link.resize((width, height), Image.Resampling.LANCZOS)\n",
    "  loaded_image = np.expand_dims(loaded_image, axis = 0)\n",
    "  return loaded_image\n",
    "\n",
    "\n",
    "def load_image_colab(image_name):\n",
    "  \"\"\" Load an image from the default Colab directory, resize it to CIFAR-10 resolution (32x32), and add a batch dimension.\n",
    "\n",
    "  :param image_name: The name of the image file located in the Colab default directory (e.g., \"/content/...\").\n",
    "  :type image_name: str\n",
    "\n",
    "  :return: The loaded and resized image as a numpy array with an added batch dimension.\n",
    "  :rtype: np.ndarray\n",
    "  \"\"\"\n",
    "\n",
    "  # Default Colab folder: \"/content/...\"\n",
    "  imageFile = \"/content/\" + image_name # taking a file with original size\n",
    "  im_from_fold = Image.open(imageFile) # if you do it from colab folder\n",
    "  # Adjust width and height to CIFAR10 resolution\n",
    "  width = 32\n",
    "  height = 32\n",
    "  loaded_image = np.array(im_from_fold.resize((width, height), Image.Resampling.LANCZOS))\n",
    "  loaded_image = np.expand_dims(loaded_image, axis = 0)\n",
    "  return loaded_image\n",
    "#Function to plot the training\n",
    "def plot_losses(train_losses: List,\n",
    "                test_losses: List,\n",
    "                train_accuracies: List,\n",
    "                test_accuracies: List,\n",
    "                title: str):\n",
    "  \"\"\" Plot the training and testing losses and accuracies over epochs.\n",
    "\n",
    "  :param train_losses: A list of training loss values recorded over each epoch.\n",
    "  :type train_losses: List[float]\n",
    "\n",
    "  :param test_losses: A list of testing loss values recorded over each epoch.\n",
    "  :type test_losses: List[float]\n",
    "\n",
    "  :param train_accuracies: A list of training accuracy values recorded over each epoch.\n",
    "  :type train_accuracies: List[float]\n",
    "\n",
    "  :param test_accuracies: A list of testing accuracy values recorded over each epoch.\n",
    "  :type test_accuracies: List[float]\n",
    "\n",
    "  :param title: The title for the plot, typically describing the training session.\n",
    "  :type title: str\n",
    "\n",
    "  :return: None\n",
    "  :rtype: None\n",
    "  \"\"\"\n",
    "\n",
    "  # Plot the Training History\n",
    "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,5))\n",
    "  fig.suptitle(title)\n",
    "  ax1.plot(train_accuracies, label=\"Train\")\n",
    "  ax1.plot(test_accuracies, label=\"Test\")\n",
    "  ax1.set(xlabel='Epoch', ylabel='Accuracy')\n",
    "  ax1.legend(loc=\"upper left\")\n",
    "  ax2.plot(train_losses, label='Train')\n",
    "  ax2.plot(test_losses, label='Test')\n",
    "  ax2.set(xlabel='Epoch', ylabel='Loss')\n",
    "  ax2.legend(loc=\"upper right\")\n",
    "\n",
    "def plot_confusion_matrix(model, dataloader, use_logits_and_one_hot=False, labels=None):\n",
    "    \"\"\" Plot the confusion matrix for a model's predictions on a dataset.\n",
    "\n",
    "    :param model: The PyTorch model used to generate predictions.\n",
    "    :type model: torch.nn.Module\n",
    "\n",
    "    :param dataloader: The dataloader providing the dataset for generating predictions.\n",
    "    :type dataloader: torch.utils.data.DataLoader\n",
    "\n",
    "    :param use_logits_and_one_hot: If True, applies softmax to model outputs and expects one-hot encoded labels.\n",
    "    :type use_logits_and_one_hot: bool, optional\n",
    "\n",
    "    :param labels: Optional dictionary mapping class indices to human-readable labels for display in the confusion matrix.\n",
    "    :type labels: Dict[int, str], optional\n",
    "\n",
    "    :return: None\n",
    "    :rtype: None\n",
    "    \"\"\"\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Get predictions\n",
    "            preds = model(X)\n",
    "            if use_logits_and_one_hot:\n",
    "                preds = F.softmax(preds, dim=1)\n",
    "\n",
    "            # Check if preds and y have expected dimensions\n",
    "            if preds.dim() == 1:\n",
    "                preds = preds.unsqueeze(0)  # Add batch dimension if missing\n",
    "\n",
    "            # Get the predicted class (argmax over class dimension)\n",
    "            pred_classes = preds.argmax(dim=1).cpu().numpy()\n",
    "            all_preds.extend(pred_classes)\n",
    "\n",
    "            # Convert labels to one-hot encoding if necessary, then flatten to match predictions\n",
    "            if use_logits_and_one_hot:\n",
    "                if y.dim() == 1:  # Ensure y has one-hot encoded dimension if expected\n",
    "                    y = F.one_hot(y, num_classes=preds.shape[1])\n",
    "                true_classes = y.argmax(dim=1).cpu().numpy()\n",
    "            else:\n",
    "                true_classes = y.cpu().numpy()\n",
    "\n",
    "            # Store true labels\n",
    "            all_labels.extend(true_classes)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # Get class names for display if labels dictionary is provided\n",
    "    display_labels = [labels[i] for i in range(len(labels))] if labels else None\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)\n",
    "    disp.plot(cmap=plt.cm.Blues, xticks_rotation=45)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VZ04ciTns6J"
   },
   "source": [
    "## 2. Normalize Images (1 Point)\n",
    "Before we start with the classification, we want to normalize our training dataset to have approximately zero mean ($\\mu=0$) and unit variance ($\\sigma=1$). For this, we need to calculate the mean and standard deviation of the training dataset. Your task is to create the function `calculate_mean_std` which takes a dataset as input. The outputs should be the two tuples `mean` and `std`. Both should be calculated per color channel. Only use the standard numpy functionality to implement this function (e.g. `np.mean()`, `np.var()`, `np.std()`, etc.). These values should be in [0, 1]. This is because when training the images are automatically converted to the range [0, 1], but when accessing them via trainset.data they are in the range [0, 255]. The values you calculate with this function should be used inside of your models to normalize the input data. Feel free to calculate the values once, and then hard-code them in your models.\n",
    "\n",
    "You can find more detailed explanation of why we do normalization in this video by Andrew Ng: [Andrew Ng - Normalizing Inputs](https://www.youtube.com/watch?v=FDCfw-YqWTE)\n",
    "\n",
    "**IMPORTANT:** Use the same mean and and standard deviation you get from the training set also for the test set, because we want our training and test data to go through the same transformation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HciMNSGBrYa9"
   },
   "source": [
    "def calculate_mean_std(dataset: torch.utils.data.Dataset) -> Tuple[Tuple, Tuple]:\n",
    "  \"\"\" Calculate the mean and standard deviation of the dataset\n",
    "\n",
    "  :param dataset: The input dataset to calculate the mean and std of\n",
    "  :type dataset: torch.utils.data.Dataset\n",
    "\n",
    "  :return: (mean, std)\n",
    "    mean: The mean of the dataset per color channel\n",
    "    std: The standard deviation of the dataset per color channel\n",
    "  :rtype: Tuple(mean, std)\n",
    "    mean: Tuple with shape (3,)\n",
    "    std:  Tuple with shape (3,)\n",
    "  \"\"\"\n",
    "  ###################################\n",
    "  # Write your own code here #\n",
    "  data = dataset.data.astype(np.float32)\n",
    "  data /= 255.0\n",
    "  mean, std = np.mean(data, axis = (0, 1, 2)), np.std(data, axis = (0, 1, 2))\n",
    "  mean = tuple(mean)\n",
    "  std = tuple(std)\n",
    "\n",
    "  ###################################\n",
    "  return mean, std\n",
    "\n",
    "mean, std = calculate_mean_std(trainset)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIldb9_Ptw0o"
   },
   "source": [
    "## 3. Loss Function (1 Point)\n",
    "Implement the cross-entropy loss in the function `my_crossentropy` with the mathematical functions defined in PyTorch. Its inputs are the tensors `predictions` and `labels`. The `prediction` tensor consists of the unnormalized prediction values for each class (the output of our network). The `label` tensor holds the true label for each training image in the range [0, `nr_of_classes -1`]. The output tensor should be the mean cross entropy loss over the whole miniset `(number_of_predictions,)`. You should use the functions provided in the PyTorch e.g. `torch.sum()` (https://pytorch.org/docs/stable/generated/torch.sum.html). Don't use the built-in crossentropy loss of PyTorch. For the formulas of the cross entropy loss, you can look at the formulas here: https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html. You only need to implement \"mean\" reduction. Do not use functions like `F.log_softmax` or `F.cross_entropy`. For debugging you can generate tensors and compare the output of your function with `F.cross_entropy`.\n",
    "\n",
    "This video gives a good explanation about the cross-entropy loss: https://youtu.be/ueO_Ph0Pyqk"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WVRTYOzEt8yQ"
   },
   "source": [
    "def my_cross_entropy(predictions, labels):\n",
    "  \"\"\" Calculate the categorical crossentropy loss between the labels and the prediction\n",
    "\n",
    "  :param predictions: Unnormalized prediction values of classes\n",
    "  :type predictions: torch.Tensor with shape (batch_size, num_classes) and dtype = torch.float32\n",
    "\n",
    "  :param labels: The class index of each datapoint in the range (0, num_classes)\n",
    "  :type labels: torch.Tensor with shape (batch_size) and dtype = torch.long\n",
    "\n",
    "  :return: Categorical crossentropy loss as a scalar\n",
    "  :rtype: torch.Tensor with shape [] (scalar) and dtype = torch.float32\n",
    "  \"\"\"\n",
    "  ###################################\n",
    "  # Write your own code here #\n",
    "  max_logits = torch.max(predictions, dim=1, keepdim=True)[0]\n",
    "  shifted_logits = predictions - max_logits\n",
    "  exp_shifted = torch.exp(shifted_logits)\n",
    "  sum_exp_shifted = torch.sum(exp_shifted, dim=1, keepdim=True)\n",
    "  logsumexp = torch.log(sum_exp_shifted) + max_logits.squeeze()\n",
    "\n",
    "  correct_cl_log = predictions[torch.arange(predictions.size(0)), labels]\n",
    "  neg_log_hood = logsumexp - correct_cl_log\n",
    "  loss = torch.mean(neg_log_hood)\n",
    "\n",
    "\n",
    "\n",
    "  ###################################\n",
    "  return loss"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVgoG2uG21Kg"
   },
   "source": [
    "##4. Linear Classifier (1 Point)\n",
    "\n",
    "As a first classifier, we want to train a simple network with only one layer (no hidden layers). A fully-connected (also called dense or linear) layer takes each input value (each pixel intensity) multiplies it with a weight and adds a bias term for each output neuron. The number of output neurons is the number of classes. The output is a score of how likely the input is part of the class. An animation of the process is shown here: https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#3\n",
    "\n",
    "To build the network, we will use the PyTorch Module class which is documented here: https://pytorch.org/docs/stable/generated/torch.nn.Module.html Classes in Python are very similar to other object-oriented programming languages such as Java or C++. Our class `LinearClassifier` inherits attributes from the class `nn.Module`. We will overwrite the `__init__` function which is always called when you create an instance of a class. You should create your layers there. The `self` keyword represents the instance of the class itself. We can use it to access attributes in different methods. E.g. if we want to create a variable in `__init__` and use it in the method forward we could do it with `self.test = 5`. We also pass the mean and standard deviation to the init function that we calculate over the whole trainset. These should be used to normalize the input of the network. In the method forward we use the variable `x` as an input for the neural network and perform one forward path return the output of the network.\n",
    "\n",
    "You should use the mean and standard deviation of the dataset you calculated before to normalize the input in your network."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k7eoRWpp3AVC"
   },
   "source": [
    "class LinearClassifier(nn.Module):\n",
    "  def __init__(self, mean: Tuple, std: Tuple):\n",
    "    super().__init__()\n",
    "    ###################################\n",
    "    # Write your own code here #\n",
    "    self.mean = torch.tensor(mean).view(1,-1,1,1)\n",
    "    self.std = torch.tensor(std).view(1,-1,1,1)\n",
    "\n",
    "    self.num_classes = 10\n",
    "    self.num_features = 3 * 32 * 32\n",
    "\n",
    "    self.linear = nn.Linear(self.num_features, self.num_classes)\n",
    "\n",
    "    ###################################\n",
    "\n",
    "  def forward(self, x):\n",
    "    ###################################\n",
    "    # Write your own code here #\n",
    "    x = (x - self.mean.to(x.device)) / self.std.to(x.device)\n",
    "\n",
    "    x = x.view(x.size(0), -1)\n",
    "\n",
    "    x = self.linear(x)\n",
    "\n",
    "    ###################################\n",
    "    return x"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1UduHsN87Grm"
   },
   "source": [
    "# Here we will define a loop for training and testing.\n",
    "# It will also return a history of the losses to plot the training process.\n",
    "# Set use_logits_and_one_hot if you’re using MSELoss with probabilities and\n",
    "# one-hot encoded labels. Use False for CrossEntropyLoss\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, use_logits_and_one_hot=False):\n",
    "    \"\"\" Training loop for a model with optional use of logits and one-hot encoded labels.\n",
    "\n",
    "    :param dataloader: The dataloader providing the training dataset in batches.\n",
    "    :type dataloader: torch.utils.data.DataLoader\n",
    "\n",
    "    :param model: The PyTorch model to be trained.\n",
    "    :type model: torch.nn.Module\n",
    "\n",
    "    :param loss_fn: The loss function used to compute the training loss.\n",
    "    :type loss_fn: torch.nn.Module\n",
    "\n",
    "    :param optimizer: The optimizer for updating model parameters.\n",
    "    :type optimizer: torch.optim.Optimizer\n",
    "\n",
    "    :param use_logits_and_one_hot: If True, converts logits to probabilities and one-hot encodes labels, useful for MSELoss.\n",
    "                                   Set to False for CrossEntropyLoss or similar functions.\n",
    "    :type use_logits_and_one_hot: bool, optional\n",
    "\n",
    "    :return: A tuple containing the average training loss and accuracy over the epoch.\n",
    "    :rtype: Tuple[float, float]\n",
    "    \"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss = 0.0\n",
    "    train_accuracy = 0.0\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        pred = model(X)\n",
    "\n",
    "        # Adjust predictions and labels based on `use_logits_and_one_hot`\n",
    "        if use_logits_and_one_hot:\n",
    "            pred = F.softmax(pred, dim=1)  # Convert logits to probabilities for MSELoss\n",
    "            y = one_hot_encode(y, num_classes=pred.shape[1])  # One-hot encode labels for MSELoss\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_accuracy += (pred.argmax(1) == y.argmax(1) if use_logits_and_one_hot else pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            print()\n",
    "\n",
    "    train_loss /= num_batches\n",
    "    train_accuracy /= size\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "# Updated test loop with logits and one-hot handling\n",
    "def test_loop(dataloader, model, loss_fn, use_logits_and_one_hot=False):\n",
    "    \"\"\" Test loop to evaluate a model's performance, with optional handling of logits and one-hot encoded labels.\n",
    "\n",
    "    :param dataloader: The dataloader providing the testing dataset in batches.\n",
    "    :type dataloader: torch.utils.data.DataLoader\n",
    "\n",
    "    :param model: The PyTorch model to be evaluated.\n",
    "    :type model: torch.nn.Module\n",
    "\n",
    "    :param loss_fn: The loss function used to compute the testing loss.\n",
    "    :type loss_fn: torch.nn.Module\n",
    "\n",
    "    :param use_logits_and_one_hot: If True, converts logits to probabilities and one-hot encodes labels, suitable for MSELoss.\n",
    "                                   Set to False for CrossEntropyLoss or similar functions.\n",
    "    :type use_logits_and_one_hot: bool, optional\n",
    "\n",
    "    :return: A tuple containing the average test loss and accuracy over the dataset.\n",
    "    :rtype: Tuple[float, float]\n",
    "    \"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, test_accuracy = 0, 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "\n",
    "            # Adjust predictions and labels based on `use_logits_and_one_hot`\n",
    "            if use_logits_and_one_hot:\n",
    "                pred = F.softmax(pred, dim=1)  # Convert logits to probabilities for MSELoss\n",
    "                y = one_hot_encode(y, num_classes=pred.shape[1])  # One-hot encode labels for MSELoss\n",
    "\n",
    "            # Compute loss\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            test_accuracy += (pred.argmax(1) == y.argmax(1) if use_logits_and_one_hot else pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    test_accuracy /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*test_accuracy):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss, test_accuracy"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDeRRIXQ9PUU"
   },
   "source": [
    "This command starts the actual training. Make sure you selected the hardware accelarator GPU in Runtime -> Change Runtime type. One epoch should take below 20 seconds.\n",
    "\n",
    "Run the training for about 20 epochs which should get you to >30% validation accuracy. If the model doesn't go above ~10% (random guessing), check your normalization and the activation function of the output_layer."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0gCPVEV077M4"
   },
   "source": [
    "# Calculate mean and standard deviation to pass to the network\n",
    "mean, std = calculate_mean_std(trainset)\n",
    "\n",
    "# Initialize the model and move it to the GPU if activated\n",
    "linear_model = LinearClassifier(mean=mean, std=std).to(device)\n",
    "learning_rate = 0.01\n",
    "epochs = 20\n",
    "\n",
    "# We use your cross entropy lossfunction.\n",
    "# If you cannot get it to work, you can replace it with nn.CrossEntropyLoss()\n",
    "loss_fn_linear = my_cross_entropy\n",
    "#loss_fn_linear = nn.MSELoss()\n",
    "\n",
    "# As an optimizer we use Stochastic Gradient Descent\n",
    "optimizer_linear = torch.optim.SGD(linear_model.parameters(),\n",
    "                                   lr=learning_rate)\n",
    "\n",
    "# Run the test_loop once to verify our model is not trained already\n",
    "test_loop(testloader,\n",
    "          linear_model,\n",
    "          loss_fn_linear,\n",
    "          use_logits_and_one_hot=False)\n",
    "\n",
    "\n",
    "# Lists to log the losses during the training process\n",
    "train_losses_linear = []\n",
    "train_accuracies_linear = []\n",
    "\n",
    "test_losses_linear = []\n",
    "test_accuracies_linear = []\n",
    "\n",
    "for t in range(epochs):\n",
    "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "  train_loss, train_acc = train_loop(trainloader,\n",
    "                                     linear_model,\n",
    "                                     loss_fn_linear,\n",
    "                                     optimizer_linear,\n",
    "                                     use_logits_and_one_hot=False)\n",
    "  test_loss, test_acc = test_loop(testloader,\n",
    "                                  linear_model,\n",
    "                                  loss_fn_linear,\n",
    "                                  use_logits_and_one_hot=False)\n",
    "\n",
    "  train_losses_linear.append(train_loss)\n",
    "  train_accuracies_linear.append(train_acc)\n",
    "\n",
    "  test_losses_linear.append(test_loss)\n",
    "  test_accuracies_linear.append(test_acc)\n",
    "print(\"Done!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECSCU3JY-Cm-"
   },
   "source": [
    "We can also plot the training process. Think a bit about what you are seeing here (you will also need to write about it for the documentation)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VYxwsFAg9NPV"
   },
   "source": [
    "plot_losses(train_losses_linear,\n",
    "            test_losses_linear,\n",
    "            train_accuracies_linear,\n",
    "            test_accuracies_linear,\n",
    "            \"Linear Classifier\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfhRmlf02tzT"
   },
   "source": [
    "We can also have a look at some predictions of our model of the test set. The function `plot_predictions(dataloader, model_name, class_name=None)` plots predictions of of random images of the test set with our model. The input data should be a dataloader. By specifying the optional parameter class_name, only correct predictions, false positives and false negatives of this class will be plotted. Feel free to change the parameters below. In the image below you can see an example output of the function with the `class_name='horse'` for a different model.\n",
    "You can now also set the paramter \"sort_prediction = True\" to get images with the highest predictions.\n",
    "\n",
    "![alt text](https://owncloud.tuwien.ac.at/index.php/apps/files_sharing/ajax/publicpreview.php?x=2193&y=855&a=true&file=horse_predictions.png&t=S2kIp8E9DGylCns&scalingup=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UoBVcJMd18tz"
   },
   "source": [
    "plot_predictions(testloader, linear_model, labels=class_labels)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UN5H9_5_19c3"
   },
   "source": [
    "plot_predictions(testloader, linear_model, class_name='ship', labels=class_labels)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glNWk1kX-QnX"
   },
   "source": [
    "##5. Multilayer Perceptron (1 Point)\n",
    "The last model with only one layer reached appr. 30% of validation accuracy. It is already better than random guessing but not really satisfactory. Now it's time to add the \"Deep\" to Deep Learning. Create a model with multiple dense layers (a multilayer perceptron) with ReLu activation in the hidden layers and train it again for about 30 Epochs. The exact structure of the model is up to you, a good starting point is a layer with 256 units, followed by another layer with 128 units and followed by the output layer. This model should reach around 50% of validation accuracy. Training time is dependent on your model but should be below 20s per epoch."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "E2kVpgwi-h6F"
   },
   "source": [
    "class MultiLayerPerceptron(nn.Module):\n",
    "  def __init__(self, mean: Tuple, std: Tuple):\n",
    "    super().__init__()\n",
    "    ###################################\n",
    "    # Write your own code here #\n",
    "    self.mean = torch.tensor(mean).view(1, -1, 1, 1)\n",
    "    self.std = torch.tensor(std).view(1, -1, 1, 1)\n",
    "\n",
    "    self.num_features = 3 * 32 * 32\n",
    "\n",
    "    self.fc1 = nn.Linear(self.num_features, 256)\n",
    "    self.fc2 = nn.Linear(256, 128)\n",
    "    self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "\n",
    "    ###################################\n",
    "  def forward(self, x):\n",
    "    ###################################\n",
    "    # Write your own code here #\n",
    "    x = (x - self.mean.to(x.device)) / self.std.to(x.device)\n",
    "    x = x.view(x.size(0), -1)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "\n",
    "    ###################################\n",
    "    return x\n",
    "\n",
    "# Calculate mean and standard deviation to pass to the network\n",
    "mean, std = calculate_mean_std(trainset)\n",
    "\n",
    "# Initialize the model and Move it to the GPU if available\n",
    "mlp_model = MultiLayerPerceptron(mean=mean, std=std).to(device)\n",
    "\n",
    "\n",
    "# Adjust these parameters if necessary\n",
    "epochs = 30\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "# As an optimizer we use Stochastic Gradient Descent\n",
    "optimizer_mlp = torch.optim.SGD(mlp_model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn_mlp = nn.CrossEntropyLoss()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mXmrDQ8H-2-z"
   },
   "source": [
    "# Actual Training\n",
    "\n",
    "# Run the test_loop once to verify our model is not trained already\n",
    "test_loop(testloader, mlp_model, loss_fn_mlp)\n",
    "\n",
    "# Lists to log the losses during the training process\n",
    "train_losses_mlp = []\n",
    "train_accuracies_mlp = []\n",
    "\n",
    "test_losses_mlp = []\n",
    "test_accuracies_mlp = []\n",
    "\n",
    "for t in range(epochs):\n",
    "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "  train_loss, train_acc = train_loop(trainloader,\n",
    "                                     mlp_model,\n",
    "                                     loss_fn_mlp,\n",
    "                                     optimizer_mlp)\n",
    "\n",
    "  test_loss, test_acc = test_loop(testloader,\n",
    "                                  mlp_model,\n",
    "                                  loss_fn_mlp)\n",
    "\n",
    "  train_losses_mlp.append(train_loss)\n",
    "  train_accuracies_mlp.append(train_acc)\n",
    "\n",
    "  test_losses_mlp.append(test_loss)\n",
    "  test_accuracies_mlp.append(test_acc)\n",
    "print(\"Done!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tKqmVKy5_Xmp"
   },
   "source": [
    "plot_losses(train_losses_mlp,\n",
    "            test_losses_mlp,\n",
    "            train_accuracies_mlp,\n",
    "            test_accuracies_mlp,\n",
    "            \"Multilayer Perceptron\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1wcsKKv_pIM"
   },
   "source": [
    "## 6. MLP with Regularization (1 Point)\n",
    "To counter the problem of overfitting, you should add measures for regularization. Create a new model based on your MLP from the last point which includes at least one regularization technique. It should improve the validation accuracy slightly."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eb6ZJ3ul_n3R"
   },
   "source": [
    "class MultiLayerPerceptronRegularization(nn.Module):\n",
    "  def __init__(self, mean: Tuple, std: Tuple):\n",
    "    super().__init__()\n",
    "    ###################################\n",
    "    # Write your own code here #\n",
    "    self.mean = torch.tensor(mean).view(1, -1, 1, 1)\n",
    "    self.std = torch.tensor(std).view(1, -1, 1, 1)\n",
    "    self.num_features = 3 * 32 * 32\n",
    "\n",
    "    self.fc1 = nn.Linear(self.num_features, 256)\n",
    "    self.dropout1 = nn.Dropout(p=0.5)\n",
    "    self.fc2 = nn.Linear(256, 128)\n",
    "    self.dropout2 = nn.Dropout(p=0.5)\n",
    "    self.fc3 = nn.Linear(128, 10)\n",
    "    ###################################\n",
    "  def forward(self, x):\n",
    "    ###################################\n",
    "    # Write your own code here #\n",
    "    x = (x - self.mean.to(x.device)) / self.std.to(x.device)\n",
    "    x = x.view(x.size(0), -1)\n",
    "\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = self.dropout1(x)\n",
    "\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.dropout2(x)\n",
    "\n",
    "    x = self.fc3(x)\n",
    "\n",
    "\n",
    "    ###################################\n",
    "    return x\n",
    "\n",
    "# Calculate mean and standard deviation to pass to the network\n",
    "mean, std = calculate_mean_std(trainset)\n",
    "\n",
    "# Initialize model and move to the GPU if available\n",
    "mlp_model_reg = MultiLayerPerceptronRegularization(mean=mean, std=std).to(device)\n",
    "\n",
    "# Adjust these parameters if necessary\n",
    "epochs = 30\n",
    "learning_rate = 0.01\n",
    "\n",
    "# As an optimizer we use Stochastic Gradient Descent.\n",
    "# You can change its parameters here\n",
    "optimizer_mlp_reg = torch.optim.SGD(mlp_model_reg.parameters(), lr=learning_rate)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6U4T30xs_7jS"
   },
   "source": [
    "# Actual Training\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn_mlp_reg = nn.CrossEntropyLoss()\n",
    "\n",
    "# Run the test_loop once to verify our model is not trained already\n",
    "test_loop(testloader, mlp_model_reg, loss_fn_mlp_reg)\n",
    "\n",
    "# Lists to log the losses during the training process\n",
    "train_losses_mlp_reg = []\n",
    "train_accuracies_mlp_reg = []\n",
    "\n",
    "test_losses_mlp_reg = []\n",
    "test_accuracies_mlp_reg = []\n",
    "\n",
    "for t in range(epochs):\n",
    "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "  train_loss, train_acc = train_loop(trainloader,\n",
    "                                     mlp_model_reg,\n",
    "                                     loss_fn_mlp_reg,\n",
    "                                     optimizer_mlp_reg)\n",
    "  test_loss, test_acc = test_loop(testloader,\n",
    "                                  mlp_model_reg,\n",
    "                                  loss_fn_mlp_reg)\n",
    "\n",
    "  train_losses_mlp_reg.append(train_loss)\n",
    "  train_accuracies_mlp_reg.append(train_acc)\n",
    "\n",
    "  test_losses_mlp_reg.append(test_loss)\n",
    "  test_accuracies_mlp_reg.append(test_acc)\n",
    "print(\"Done!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6qQxiB4bBKZm"
   },
   "source": [
    "plot_losses(train_losses_mlp_reg,\n",
    "            test_losses_mlp_reg,\n",
    "            train_accuracies_mlp_reg,\n",
    "            test_accuracies_mlp_reg,\n",
    "            \"MLP with Regulariztion\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKEouElBAaL4"
   },
   "source": [
    "## 7. Convolutional Neural Network (2 Point)\n",
    "When converting our images to vectors, all spatial information is lost. A convolutional neural network takes tensors as input and computes features that make use of spatial information. In this exercise implement a neural network as specified in the image below. Add regularization techniques until you reach at least 75% of validation accuracy with a training time of below 30s per epoch.\n",
    "\n",
    "Notes: 3x3 Conv X refers to a Conv2D layer with kernel 3x3 and X units.\n",
    "Maxpool /2 refers to a MaxPool layer with kernel=(2,2) and stride=2.\n",
    "\n",
    "\n",
    "![Network Architecture](https://owncloud.tuwien.ac.at/index.php/apps/files_sharing/ajax/publicpreview.php?x=1747&y=643&a=true&file=ex4_cnn_architecture.png&t=UpMwi8LlXvwKJ2e&scalingup=0)\n",
    "\n",
    "Figure 3: Network Architecture\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sSjIKCdGAWUj"
   },
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "  def __init__(self, mean: Tuple, std: Tuple):\n",
    "    super().__init__()\n",
    "    ###################################\n",
    "    # Write your own code here #\n",
    "    self.mean = torch.tensor(mean).view(1, -1, 1, 1)\n",
    "    self.std = torch.tensor(std).view(1, -1, 1, 1)\n",
    "\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn1 = nn.BatchNorm2d(32)\n",
    "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn2 = nn.BatchNorm2d(32)\n",
    "    self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn3 = nn.BatchNorm2d(64)\n",
    "    self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn4 = nn.BatchNorm2d(64)\n",
    "    self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
    "    self.dropout1 = nn.Dropout(p=0.5)\n",
    "    self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    ###################################\n",
    "  def forward(self, x):\n",
    "    ###################################\n",
    "    # Write your own code here #\n",
    "    x = (x - self.mean.to(x.device)) / self.std.to(x.device)\n",
    "\n",
    "    x = F.relu(self.bn1(self.conv1(x)))\n",
    "    x = F.relu(self.bn2(self.conv2(x)))\n",
    "    x = self.pool1(x)\n",
    "\n",
    "    x = F.relu(self.bn3(self.conv3(x)))\n",
    "    x = F.relu(self.bn4(self.conv4(x)))\n",
    "    x = self.pool2(x)\n",
    "\n",
    "    x =  x.view(x.size(0), -1)\n",
    "\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = self.dropout1(x)\n",
    "    x = self.fc2(x)\n",
    "\n",
    "\n",
    "    ###################################\n",
    "    return x\n",
    "\n",
    "# Calculate mean and standard deviation to pass to the network\n",
    "mean, std = calculate_mean_std(trainset)\n",
    "\n",
    "# Initialize the model and Move it to the GPU if available\n",
    "cnn_model = CNNClassifier(mean=mean, std=std).to(device)\n",
    "\n",
    "# Adjust these parameters if necessary\n",
    "epochs = 30\n",
    "learning_rate = 0.001\n",
    "\n",
    "# As an optimizer we use Adam\n",
    "optimizer_cnn = torch.optim.Adam(cnn_model.parameters(), lr=learning_rate)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jnMRVjMEBbx6"
   },
   "source": [
    "# Actual Training\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn_cnn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Run the test_loop once to verify our model is not trained already\n",
    "test_loop(testloader,\n",
    "          cnn_model,\n",
    "          loss_fn_cnn)\n",
    "\n",
    "# Lists to log the losses during the training process\n",
    "train_losses_cnn = []\n",
    "train_accuracies_cnn = []\n",
    "\n",
    "test_losses_cnn = []\n",
    "test_accuracies_cnn = []\n",
    "\n",
    "for t in range(epochs):\n",
    "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "  train_loss, train_acc = train_loop(trainloader,\n",
    "                                     cnn_model,\n",
    "                                     loss_fn_cnn,\n",
    "                                     optimizer_cnn)\n",
    "  test_loss, test_acc = test_loop(testloader,\n",
    "                                  cnn_model,\n",
    "                                  loss_fn_cnn)\n",
    "\n",
    "  train_losses_cnn.append(train_loss)\n",
    "  train_accuracies_cnn.append(train_acc)\n",
    "\n",
    "  test_losses_cnn.append(test_loss)\n",
    "  test_accuracies_cnn.append(test_acc)\n",
    "print(\"Done!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TUHiSv_HBoQc"
   },
   "source": [
    "plot_losses(train_losses_cnn,\n",
    "            test_losses_cnn,\n",
    "            train_accuracies_cnn,\n",
    "            test_accuracies_cnn,\n",
    "            \"Convolutional Neural Network\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVuQI8VMBzFt"
   },
   "source": [
    "## 8. Transfer Learning (2 Point)\n",
    "In the next step we want to use a model which is already pre-trained on a large dataset (Imagenet) and finetune it for the CIFAR10 dataset. PyTorch already provides us with multiple pretrained models (see https://pytorch.org/vision/stable/models.html). Your task is to take the ResNet50 model and **only** retrain the last layer. You should upsample the images first because ResNet is trained on Images with the resolution of (224, 224). Training with this resolution takes a substantial amount of time with not that much gain. A resolution of (128, 128) is a good compromise between accuracy and training time. You can use the `Resize` transform from `pytorch.transforms`. You should also normalize the images the same way as ResNet does. This approach should get you to over 80% of validation accuracy. Training time will take much longer here (~120 seconds per epoch), so you only need to train for 5-10 epochs. We won't provide a template for this part again, just add the code for loading the model,  exchanging the last layer and training it in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8A-y8FyJDE_g"
   },
   "source": [
    "from torchvision import models\n",
    "###################################\n",
    "# Write your own code here #\n",
    "\n",
    "trainset_original = trainset\n",
    "testset_original = testset\n",
    "trainloader_original = trainloader\n",
    "testloader_original = testloader\n",
    "\n",
    "\n",
    "# Define the transformations, including resizing and normalization\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize images to 128x128\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ResNet's normalization mean\n",
    "                         std=[0.229, 0.224, 0.225])   # ResNet's normalization std\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize images to 128x128\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ResNet's normalization mean\n",
    "                         std=[0.229, 0.224, 0.225])   # ResNet's normalization std\n",
    "])\n",
    "\n",
    "# Load the CIFAR-10 datasets with the defined transforms\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                        train=True,\n",
    "                                        download=True,\n",
    "                                        transform=transform_train)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                       train=False,\n",
    "                                       download=True,\n",
    "                                       transform=transform_test)\n",
    "\n",
    "# Create data loaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=64,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                         batch_size=64,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=2)\n",
    "\n",
    "# Load the pre-trained ResNet50 model\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "\n",
    "# Replace the last layer to match the number of classes in CIFAR-10\n",
    "num_ftrs = resnet50.fc.in_features\n",
    "resnet50.fc = nn.Linear(num_ftrs, 10)  # CIFAR-10 has 10 classes\n",
    "\n",
    "# Freeze all layers except the last one\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in resnet50.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet50 = resnet50.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet50.fc.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5  # You can adjust the number of epochs as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    resnet50.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    # Iterate over data\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = resnet50(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistics\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    # Compute epoch loss and accuracy\n",
    "    epoch_loss = running_loss / len(trainset)\n",
    "    epoch_acc = running_corrects.double() / len(trainset)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs} - Training Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    # Evaluate on test set\n",
    "    resnet50.eval()\n",
    "    test_loss = 0.0\n",
    "    test_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = resnet50(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            test_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    test_loss = test_loss / len(testset)\n",
    "    test_acc = test_corrects.double() / len(testset)\n",
    "\n",
    "    print(f'Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}')\n",
    "\n",
    "###################################"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzDdwyTAZWh0"
   },
   "source": [
    "# Experiments\n",
    "Here you can add code that you need for your documentation. Feel free to play around in this section with the models, your own images, create new models, data augmentation, different datasets, ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ETFyO0HRZYbG",
    "collapsed": true
   },
   "source": [
    "# Load an image from that link and get Top-5 predictions\n",
    "test_im = load_image_link('https://pixy.org/src/465/4657011.jpg')\n",
    "plt.imshow(test_im[0,...])\n",
    "\n",
    "#vec_im = vectorize_images(test_im)\n",
    "predict_image(cnn_model, test_im, transform=transforms.ToTensor())\n",
    "\n",
    "# prediction with a model\n",
    "img_torch = torch.from_numpy(np.transpose(test_im.astype(np.float32), (0,3,1,2))/255.)\n",
    "print(img_torch.shape)\n",
    "plt.imshow(transforms.ToPILImage()(img_torch[0]))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YBxsa20PCr2v"
   },
   "source": [
    "# If you want to mount your Google Drive to store weights or plots for example\n",
    "# you can use the commands below. Check this link for more information:\n",
    "# https://colab.research.google.com/notebooks/io.ipynb#scrollTo=u22w3BFiOveA\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Confusion Matrix"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Use original testloader for models trained on 32x32 images\n",
    "plot_confusion_matrix(linear_model, testloader_original, use_logits_and_one_hot=False, labels=class_labels)\n",
    "plot_confusion_matrix(mlp_model_reg, testloader_original, use_logits_and_one_hot=False, labels=class_labels)\n",
    "plot_confusion_matrix(cnn_model, testloader_original, use_logits_and_one_hot=False, labels=class_labels)\n",
    "\n",
    "plot_predictions(testloader_original, linear_model, class_name='airplane', labels=class_labels)\n",
    "plot_predictions(testloader_original, mlp_model_reg, class_name='cat', labels=class_labels)\n",
    "plot_predictions(testloader_original, cnn_model, class_name='dog', labels=class_labels)\n",
    "\n",
    "# Evaluate ResNet50 model\n",
    "plot_confusion_matrix(resnet50, testloader, use_logits_and_one_hot=False, labels=class_labels)\n",
    "plot_predictions(testloader, resnet50, class_name='airplane', labels=class_labels)\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}
